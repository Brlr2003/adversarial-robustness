% Thesis Metadata
% Fill in your personal information and thesis details here

% Thesis type
\MSc  % For Master of Science

% Author information
\author{Omar}{Alsafarti}
\studentid{42012418}

% Thesis titles
\title{ADVERSARIAL ATTACKS ON DEEP NEURAL NETWORKS: GENERATION, EVALUATION, AND ROBUST TRAINING}
\titleenglish{ADVERSARIAL ATTACKS ON DEEP NEURAL NETWORKS: GENERATION, EVALUATION, AND ROBUST TRAINING}
\titlealbanian{SULMET KUNDËRSHTARE NË RRJETET NEURALE TË THELLA: GJENERIMI, VLERËSIMI DHE TRAJNIMI I QËNDRUESHËM}

% Dates
\date{June 2026}
\dateenglish{June 2026}

% Supervisor
\supervisor{Assoc. Prof. Dr. Arban Uka}
\supervisorenglish{Assoc. Prof. Dr. Arban Uka}

% Department and Faculty
\department{Computer Engineering}
\departmentenglish{Computer Engineering}
\faculty{Faculty of Architecture and Engineering}
\facultyenglish{Faculty of Architecture and Engineering}

% Head of Department (for approval page)
\headofdepartment{Dr. Florenc Skuka} 


% Abstract (English)
\abstract{
Deep learning models, despite their strong performance on image classification and other tasks, are vulnerable to adversarial examples: inputs modified with tiny, human-imperceptible perturbations that cause confident misclassification. This is a practical concern for autonomous driving, biometrics, and security applications.

In this thesis, I implement three white-box adversarial attacks --- FGSM, PGD, and DeepFool --- from scratch and evaluate them on a ResNet-18 trained on CIFAR-10. The standard model reaches 94.1\% clean accuracy but collapses to 1.2\% under a 20-step PGD attack at $\epsilon = 8/255$. I then apply PGD-based adversarial training, which produces a model that holds 45.1\% accuracy under the same attack while losing 10.2 percentage points of clean accuracy. DeepFool analysis shows the standard model's decision boundaries lie just 0.248 $L_2$ from the data on average; after adversarial training, this distance increases to 0.892. The results show both how severe adversarial vulnerability is and that adversarial training offers a real, if costly, defense.
}

% Keywords (English)
\keywordsenglish{Adversarial Examples, Deep Neural Networks, FGSM, PGD, DeepFool, Adversarial Training, Robustness}

% Abstrakt (Albanian)
\abstrakt{
Modelet e mësimit të thellë (Deep Learning) arrijnë performancë të jashtëzakonshme në detyra si klasifikimi i imazheve, megjithatë ato janë të njohura për cenueshmërinë ndaj shembujve kundërshtarë (Adversarial Examples), hyrje që janë ndryshuar me ndryshime të vogla, shpesh të padukshme, të cilat shkaktojnë klasifikim të gabuar me besueshmëri të lartë. Kjo cenueshmëri ngre shqetësime serioze për sigurinë e sistemeve të përdorura në drejtimin autonom, biometrikë dhe sigurinë kibernetike.

Kjo tezë fokusohet në studimin praktik të sulmeve kundërshtare kundër modeleve të klasifikimit të imazheve. Një rrjet nervor konvolucionar (Convolutional Neural Network) ResNet-18 trajnohet në grupin e të dhënave CIFAR-10 dhe tre sulme white-box (FGSM, PGD, DeepFool) implementohen dhe krahasohen. Modeli standard arrin saktësi 94.1\% në të dhëna të pastra por bie në 1.2\% nën sulmin PGD me 20 hapa. Trajnimi kundërshtar (Adversarial Training) i bazuar në PGD aplikohet më pas, duke prodhuar një model të qëndrueshëm që ruan 45.1\% saktësi nën të njëjtin sulm, me koston e një rënieje prej 10.2 pikësh përqindjeje në saktësinë e pastër. Këto rezultate konfirmojnë ashpërsinë e cenueshmërisë kundërshtare dhe vërtetojnë trajnimin kundërshtar si një mekanizëm mbrojtës efektiv.
}

% Keywords (Albanian)
\keywords{Shembuj Kundërshtarë, Rrjete Neurale të Thella, FGSM, PGD, DeepFool, Trajnim Kundërshtar, Qëndrueshmëri}

% Acknowledgments
\acknowledgments{
I owe a great deal to my supervisor, Assoc. Prof. Dr. Arban Uka, who guided this work from start to finish. His deep knowledge of the subject and his willingness to challenge my ideas at every stage shaped both the research and my thinking about it. I am grateful for his patience and for the many hours he spent discussing this work with me.

I also want to thank my family, who put up with a lot during my studies --- late nights, missed gatherings, and the general stress of thesis writing. Their support made all of this possible. My friends and colleagues at Epoka University made the experience more enjoyable than it otherwise would have been.

Finally, I am thankful to Epoka University for giving me the opportunity to pursue this degree and for providing the resources that made the research possible.
}

% Dedication (optional - uncomment if needed)
% \dedication{
%     To my family...
% }

% Abbreviations
\abbreviations{
\begin{tabular}{ll}
AE & Adversarial Example \\
BIM & Basic Iterative Method \\
C\&W & Carlini-Wagner Attack \\
CNN & Convolutional Neural Network \\
DNN & Deep Neural Network \\
FGSM & Fast Gradient Sign Method \\
GPU & Graphics Processing Unit \\
MPS & Metal Performance Shaders \\
PGD & Projected Gradient Descent \\
PGD-AT & PGD-based Adversarial Training \\
ResNet & Residual Network \\
SGD & Stochastic Gradient Descent \\
UAP & Universal Adversarial Perturbation \\
\end{tabular}
}

% Optional: Disable table or figure lists if not needed
% \NoTableList
% \NoFigureList